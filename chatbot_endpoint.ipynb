{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    },
    "colab": {
      "name": "chatbot-endpoint.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JavIonBek/chatbot-uz/blob/main/chatbot_endpoint.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UmhkQ_MjPBDr"
      },
      "source": [
        "# Chatbot - chatting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oJ1Auozag0oQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21cb5eed-03b5-4e15-d983-78a420120d7c"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "frjH0wNld1sw"
      },
      "source": [
        "# things we need for NLP\n",
        "import nltk\n",
        "from nltk.stem.lancaster import LancasterStemmer\n",
        "stemmer = LancasterStemmer()\n",
        "\n",
        "import tensorflow as tf\n",
        "import pickle\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "397B9ZZoheNd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c37df48-7340-47f5-82c9-8f2cc55215b9"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lyYQw1o8d1s4"
      },
      "source": [
        "data = pickle.load( open( \"/content/drive/My Drive/Colab_Notebooks/Machine Learning Foundations Google/NLP/Chatbot/Chatbot-uz/chatbot-data-main.pkl\", \"rb\" ) )\n",
        "words = data['words']\n",
        "classes = data['classes']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Vejon-Od1tB"
      },
      "source": [
        "def clean_up_sentence(sentence):\n",
        "    # tokenize the pattern\n",
        "    sentence_words = nltk.word_tokenize(sentence)\n",
        "    # stem each word\n",
        "    sentence_words = [stemmer.stem(word.lower()) for word in sentence_words]\n",
        "    return sentence_words\n",
        "\n",
        "# return bag of words array: 0 or 1 for each word in the bag that exists in the sentence\n",
        "def bow(sentence, words, show_details=True):\n",
        "    # tokenize the pattern\n",
        "    sentence_words = clean_up_sentence(sentence)\n",
        "    # bag of words\n",
        "    bag = [0]*len(words)  \n",
        "    for s in sentence_words:\n",
        "        for i,w in enumerate(words):\n",
        "            if w == s: \n",
        "                bag[i] = 1\n",
        "                if show_details:\n",
        "                    print (\"found in bag: %s\" % w)\n",
        "\n",
        "    return(np.array(bag))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4jTYq5spd1tK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e93c6da9-9ef8-44aa-a2e4-3456ae66b6d7"
      },
      "source": [
        "p = bow(\"Assalomu aleykum, yaxshimisiz\", words)\n",
        "print(p)\n",
        "print(classes)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "found in bag: assalomu\n",
            "found in bag: aleyk\n",
            "[0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "['kim_san', 'qonun_buzarlikni_yuklash', 'rahmat', 'rezyume_yuborish', 'salom', 'xayr']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0OfuZLwdsTIN"
      },
      "source": [
        "global graph\n",
        "graph = tf.compat.v1.get_default_graph()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tEFmVsqcT-9x"
      },
      "source": [
        "# From chatbot-model.ipynb\n",
        "from tensorflow.python.keras.layers import deserialize, serialize\n",
        "from tensorflow.python.keras.saving import saving_utils\n",
        "\n",
        "\n",
        "def unpack(model, training_config, weights):\n",
        "  restored_model = deserialize(model)\n",
        "  if training_config is not None:\n",
        "    restored_model.compile(\n",
        "      **saving_utils.compile_args_from_training_config(\n",
        "          training_config\n",
        "      )\n",
        "    )\n",
        "  restored_model.set_weights(weights)\n",
        "  return restored_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S_Z-tM-md1tT"
      },
      "source": [
        "with open(f\"/content/drive/MyDrive/Colab_Notebooks/Machine Learning Foundations Google/NLP/Chatbot/Chatbot-uz/chatbot-model-main.pkl\", 'rb') as f:\n",
        "  model = pickle.load(f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fdISugPfd1tZ"
      },
      "source": [
        "def classify_local(sentence):\n",
        "    ERROR_THRESHOLD = 0.25\n",
        "    \n",
        "    # generate probabilities from the model\n",
        "    input_data = pd.DataFrame([bow(sentence, words)], dtype=float, index=['input'])\n",
        "    results = model.predict([input_data])[0]\n",
        "    # filter out predictions below a threshold, and provide intent index\n",
        "    results = [[i,r] for i,r in enumerate(results) if r>ERROR_THRESHOLD]\n",
        "    # sort by strength of probability\n",
        "    results.sort(key=lambda x: x[1], reverse=True)\n",
        "    return_list = []\n",
        "    for r in results:\n",
        "        return_list.append((classes[r[0]], str(r[1])))\n",
        "    # return tuple of intent and probability\n",
        "    \n",
        "    return return_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bjh1_R_sd1te",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cba4a850-6cec-4f54-af86-888b35cf1f09"
      },
      "source": [
        "classify_local('Salom, xayrli kun!')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "found in bag: salom\n",
            "found in bag: kun\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('salom', '0.9999871')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CI7A3gDWd1tj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c70fbd2b-9cf6-4b8b-af10-57c17273ef01"
      },
      "source": [
        "classify_local('Rahmat!')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "found in bag: rahm\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('rahmat', '0.999949')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3tX_x8fUd1tn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "419e222f-3a0d-4e97-9891-737605b7247d"
      },
      "source": [
        "classify_local('Juda yordami tegdi, rahmat')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "found in bag: yordam\n",
            "found in bag: rahm\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('rahmat', '0.999974')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q9ixcGMSd1ts",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97c17a31-097f-4a56-c9b1-59d45760f2d5"
      },
      "source": [
        "classify_local('Sog\\' bo\\'ling')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "found in bag: sog\n",
            "found in bag: '\n",
            "found in bag: bo'ling\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('xayr', '0.9999933')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aVxfm6f_RxDS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "980b19be-481c-4034-e9da-9b5c3abc3b63"
      },
      "source": [
        "classify_local('Qalaysiz?')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "found in bag: qalays\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('salom', '0.999871')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-BWcQ2s17CRj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69d9c127-7ed4-41d6-e411-ba9b72c0377c"
      },
      "source": [
        "classify_local('Салом')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "found in bag: салом\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('salom', '0.99972385')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8PfoUC9FkXM6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8891ca1a-6d77-4312-de0b-011d2d519ab9"
      },
      "source": [
        "classify_local('Qanday qilib qonun buzarlik haqida xabar berish mumkin?')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "found in bag: qanday\n",
            "found in bag: qilib\n",
            "found in bag: qonun\n",
            "found in bag: buzarlik\n",
            "found in bag: haqid\n",
            "found in bag: xab\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('qonun_buzarlikni_yuklash', '1.0')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mvbZAFzfUupa"
      },
      "source": [
        "## Chatting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TyACQvtGmvpC"
      },
      "source": [
        "# import our chat-bot intents file\n",
        "import json\n",
        "with open('/content/drive/MyDrive/Colab_Notebooks/Machine Learning Foundations Google/NLP/Chatbot/Chatbot-uz/intents.json') as json_data:\n",
        "    intents = json.load(json_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eJkgAKtVlGKU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9022e34-9a5c-4c17-8530-ad704d819e9b"
      },
      "source": [
        "print(intents['intents'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[{'tag': 'salom', 'patterns': ['Salom', 'Assalomu aleykum', 'Qalaysiz', 'Assalom', 'Hayrli kun', 'Салом', 'Aссалому алейкум', 'Aссалом'], 'responses': ['Sizga xursandman :) Nima bilan yordam berishim mumkin?', 'Assalomu aleykum, web saytimizga xush kelibsiz. Qanday yordam bera olaman?', 'Assalomu aleykum, qanday yordam bera olaman?'], 'context': ['']}, {'tag': 'xayr', 'patterns': ['Xayr', \"Ko'rishguncha\", \"Sog' bo'ling\", 'Хайр', 'Кўришгунча', 'Соғ бўлинг'], 'responses': [\"Omad tilayman! Yana uchrashishdan xursand bo'laman.\", \"Sog' bo'ling, ko'rishguncha :)\", \"Kuningiz yaxshi o'tsin.\", 'Xayr! Tashrifingizdan xursandmiz.'], 'context': ['']}, {'tag': 'rahmat', 'patterns': ['Rahmat', 'Raxmat', 'Kattakon rahmat', 'Yordamingiz uchun rahmat', 'Раҳмат', 'Рахмат', 'Каттакон раҳмат', 'Ёрдамингиз учун раҳмат'], 'responses': ['Men foydali bo`lishga harakat qilyapman.', 'Yordam berganimdan xursandman!', 'Arzimaydi.'], 'context': ['']}, {'tag': 'kim_san', 'patterns': ['Kim san?', 'Nima san?', 'Isming nima?', 'Ким сан?', 'Нима сан?', 'Исминг нима?'], 'responses': [\"Men ushbu saytning sun'iy aqlga ega operatoriman.\"], 'context': ['']}, {'tag': 'qonun_buzarlikni_yuklash', 'patterns': [\"Qanday qilib qonun buzarlik haqida ma'lumot xabar qilsam bo'ladi?\", \"Saytdan qanday qilib qonun buzarlik haqida ma'lumot yuklasam bo'ladi?\", 'qonun buzarlik', 'Қандай қилиб қонун бузарлик ҳақида маълумот хабар қилсам бўлади?', 'Сайтдан қандай қилиб қонун бузарлик ҳақида маълумот юкласам бўлади?', 'қонун бузарлик'], 'responses': [\"Saytning Qonun buzarliklar sahifasiga o'tib, tegishli ma'lumotlarni kiritib, ma'limot yuklashingiz mumkin.\"], 'context': ['']}, {'tag': 'rezyume_yuborish', 'patterns': [\"Qanday qilib rezyume yuborsam bo'ladi?\", 'rezyume yuborish', \"Qanday rezyume yuborsam bo'ladi?\", 'Қандай қилиб резюме юборсам бўлади?', 'резюме юбориш', 'Қандай резюме юборсам бўлади?'], 'responses': [\"Saytning Rezyume yuborish sahifasiga o'tib, kerakli ma'lumotlarni kiritish orqali rezyumengizni yuborishingiz mumkin.\"], 'context': ['']}]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQEbvN9OTjza",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6747aa58-b57f-4d6a-85f0-fc7dc93f7d17"
      },
      "source": [
        "def chat():\n",
        "  print(\"Chat boshlandi!\")\n",
        "  while True:\n",
        "    inp = input('Siz: ')\n",
        "    if inp.lower() == 'stop':\n",
        "      break\n",
        "    \n",
        "    inp = pd.DataFrame([bow(inp, words, show_details=False)], dtype=float, index=['input'])\n",
        "    results = model.predict([inp])[0]\n",
        "    results_index = np.argmax(results)\n",
        "    tag = classes[results_index]\n",
        "\n",
        "    if results[results_index] > 0.7:\n",
        "      for tg in intents['intents']:\n",
        "        if tg['tag'] == tag:\n",
        "          responses = tg['responses']\n",
        "          print('Bot:', random.choice(responses))\n",
        "    else:\n",
        "      print(\"Bot: Afsuski, Sizga yordam bera olmadim. Mutaxassis bilan bog’lanishni istaysizmi?\\n1. Ha\\n2. Yo'q\")\n",
        "      # Afsuski, Sizga yordam bera olmadim. Mutaxassis bilan bog’lanishni istaysizmi?\n",
        "      # Ha\n",
        "      # Yo’q\n",
        "      # Kechirasiz, ehtimol men Sizni noto`g`ri tushundim. Iltimos, savolni boshqacha bering va men javob berishga harakat qilaman.\n",
        "\n",
        "\n",
        "chat()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Chat boshlandi!\n",
            "Siz: salom\n",
            "Bot: Sizga xursandman :) Nima bilan yordam berishim mumkin?\n",
            "Siz: Qanday qilib qunun buzarlik haqida xabar berish mumkin?\n",
            "Bot: Saytning Qonun buzarliklar sahifasiga o'tib, tegishli ma'lumotlarni kiritib, ma'limot yuklashingiz mumkin.\n",
            "Siz: rahmat\n",
            "Bot: Arzimaydi.\n",
            "Siz: dfgdfgdfgdf\n",
            "Bot: Afsuski, Sizga yordam bera olmadim. Mutaxassis bilan bog’lanishni istaysizmi?\n",
            "1. Ha\n",
            "2. Yo'q\n",
            "Siz: salom\n",
            "Bot: Assalomu aleykum, qanday yordam bera olaman?\n",
            "Siz: xayr\n",
            "Bot: Xayr! Tashrifingizdan xursandmiz.\n",
            "Siz: stop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aWga2jzMMW7O"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LcBIlF4JptmB"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}